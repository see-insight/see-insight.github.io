## Welcome to the SEE-Insight Research Team

The SEE-Insight Research Team is lead by [Dr. Dirk Colbry](http://www.dirk.colbry.com/) in the Department of Computational Mathematics, Science and Engineering at Michigan State University.  

### Problem Description
Low-cost imaging allow researchers who rely on visual observations to digitally record experiments, resulting in huge databases of images that can be reviewed and re-reviewed over time. “Scientific image understanding” is the process of extracting scientific measurements out of images. Since the information of interest within an image changes with each new research question there is no single “universal measurement” and no single software program that can analyze every image or solve every problem. Instead, researchers must manually re-annotate images or write new analysis software every time they want to ask new questions.

Machine learning (ML) offers a way to “automatically” find a customized image analysis algorithm for new research workflows. However, traditional supervised ML approaches (e.g., Artificial Neural Networks) require large datasets of pre-annotated images for training, which creates a circular problem: researchers must manually annotate their images in order to create a training dataset so that traditional ML approaches can find an algorithm to automatically annotate their images. This can be feasible for large, well-funded projects and domains (e.g., Medical Imaging, Self-Driving Cars) but not for smaller, exploratory projects where researchers want to use their data to test simple hypotheses or ask questions that have never been studied before. During this early stage of the scientific process, which we are calling “Exploratory Image Understanding,” it is common to manually annotate image and video frame-by-frame, which is an extremely slow process subject to variations in quality and detail.

### SEE-Insight Approach

The goal of this research is to develop image understanding tools keeps the “researcher-in-the-loop” by (1) supporting immediate, manual annotation of image data while (2) working in the background to find algorithms that can help automate and speed up the workflow, allowing researchers to scale-up faster and minimizing their mean time to science. The SEE-Insight team has identified common workflows used in scientific image understanding (e.g., point selection, region segmentation, classification, counting) and is building tools that allow researchers to quickly and easily annotate their images. Simultaneously, the project is exploring approaches that work in the background to search the “algorithm space” to identify image analysis algorithms that might assist in the specific annotation workflow. If a good candidate algorithm is found the system will offer suggestions to the researcher – who can accept, adjust or reject the suggestion. In the best case, the SEE toolkit works with the researcher to automatically identify a matching algorithm that can automate the annotation process for this specific research question. In the worst case, the SEE toolkit supports the manual annotation of datasets (even if no automated algorithm is identified for the current process) and these results can be used to answer scientific questions or to feed into a more traditional ML system.
The SEE-Insight Project is researching and developing tools using the following design guidelines:

*	**_Transparent Interface Design:_** Transparent design was first outlined by Doug Norman in “Design of Everyday Things” and “The Invisible Computer.” In this context, a good interface is one where the computer becomes invisible and users can focus on what they are trying to do instead of how to do it using the computer. In the case of exploratory image understanding, transparent design allows the researcher to focus on analyzing the image rather than on the mechanics of the software.
*	**_Keeping the Researcher in the Loop:-** At every step in the analysis and annotation process, researchers can review the SEE toolkit suggestions and accept, adjust or reject them as needed. The toolkit always allows researchers to make the final decisions.
*	**_User Feedback and Confidence Measures:_** Providing feedback is key if the SEE toolkit is to gain and keep researchers’ trust. This feedback takes the form of measurements with confidence measures, which allows researchers to make an expert judgement about the likelihood of the suggested measurement being appropriate for the current question.
*	**_Feature Scaffolding:_** The toolkit is designed to provide new users with more automation and step-by-step instructions, as well as additional functionality for “power users” who have gained familiarity and trust in the toolkit.
